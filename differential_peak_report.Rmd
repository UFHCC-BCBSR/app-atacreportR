---
title: "`r params$report_title`"
subtitle: "Report Prepared by UFHCC BCB-SR"
output: 
  html_document:
    toc: true
    keep_md: false
    toc_float: false
    number_sections: true
    theme: default
    highlight: tango
    code_folding: none
params:
  report_title: "BCB-SR RNA-seq Report"  # default fallback
  params_file: 
  test_mode: false  
pandoc_args: 
  - "+RTS" 
  - "-K16000m"
  - "-RTS"
date: "`r format(Sys.time(), '%m/%d/%y')`"
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, fig.align="center")

# Load libraries
library(DESeq2)
library(pheatmap)
library(ggplot2)
library(GenomicRanges)
library(dplyr)
library(tibble)
library(edgeR)
library(limma)
library(htmltools)
library(knitr)
library(DT)
library(ggfortify)
library(scales)
library(stringr)
library(downloadthis)
source("text-config.R")
source("R/report_funcs.R", local = knitr::knit_global())
select <- dplyr::select

# Edit this for interactive use
# params_path <- '/blue/cancercenter-dept/hkates/Apps/new-atacreportR/test-input/licht-test-params.txt'
# params_path <- '/blue/cancercenter-dept/hkates/Apps/new-atacreportR/test-input/params.txt'
# params_path <- '/blue/cancercenter-dept/hkates/Apps/new-atacreportR/test-input/licht-params-from-app.txt'
# params_path <- '/blue/cancercenter-dept/hkates/Apps/new-atacreportR/test-input/NS3971-test_params.txt'
# params_path <- "/blue/cancercenter-dept/hkates/Apps/new-atacreportR/output/daphne-from-nfcore_params.txt"
#params_path <- "/blue/cancercenter-dept/hkates/Apps/new-atacreportR/output/daphne-from-peakreporter_params.txt"
#params_path <- "/blue/cancercenter-dept/hkates/Apps/new-atacreportR/output/daphne-all-in-one_params.txt"
params_path <- "/blue/cancercenter-dept/hkates/Apps/new-atacreportR/output/daphne-from-peakreporter-update_params.txt"
```

```{r parse-params, include=FALSE}
# Priority 1: Use params$params_file (passed from sbatch) - this overrides hardcoded
if (exists("params") && !is.null(params$params_file) && params$params_file != "" && file.exists(params$params_file)) {
  message("ðŸ”„ Using sbatch params file: ", basename(params$params_file))
  params_file_to_use <- params$params_file
  
# Priority 2: Fall back to hardcoded params_path (for interactive RStudio testing)
} else if (exists("params_path") && !is.null(params_path) && params_path != "" && file.exists(params_path)) {
  message("ðŸ”„ Using interactive params file: ", basename(params_path))
  params_file_to_use <- params_path
  
# Priority 3: Error - no valid params found
} else {
  stop("No valid params file found!\n\n",
       "For interactive use, set: params_path <- '/path/to/your/params.txt'\n",
       "For sbatch use, pass --params-file argument")
}

# Parse parameters
tryCatch({
  report_params <- parse_params(params_file_to_use)
}, error = function(e) {
  stop("Failed to parse params file: ", params_file_to_use, "\n",
       "Error: ", e$message)
})

message("Parameters loaded successfully from: ", basename(params_file_to_use))
```

# Project Summary

**PI**: `r report_params$PI`

**Institution**: `r report_params$Institution`

**Department**: `r report_params$Department`

**Study Contact**: `r report_params$Study_Contact`

**Project Title**: `r report_params$Project_Title`

**Study Summary**: `r report_params$Study_Summary`

**Sample type(s)**: `r report_params$Sample_Types`

**Organism**: `r report_params$Organism`

**Analysis goal(s)**: `r report_params$Analysis_Goals`

**Report-prepared-by**:  
  - `r report_params$Report_Prepared_By`
  
**Report-reviewed-by**:  
  - `r report_params$Report_Reviewed_By`

# Data Downloads

## Download Raw Sequencing Data  

Below is a link to download the raw sequencing files. These files are very large (>150GB); download only when needed. Note that you **must be logged into your UF dropbox account** for this link to work.

```{r download raw data, echo=FALSE, results="asis"}
url <- if(!is.null(report_params$raw_seq_URL)) report_params$raw_seq_URL else ""
if (url == "") {
  cat("<p><em>This file was not included in this report.</em></p>")
} else {
  cat(sprintf('<a href="%s" class="btn btn-primary" role="button" download>Download Raw Sequence Files</a>', url))
}
```

## Download Sequencing Data Quality Control Summary

MultiQC is a visualisation tool that generates a single HTML report summarising all samples in your project. Pipeline QC results are visualized in the report which collates pipeline QC from FastQC, TrimGalore, samtools flagstat, samtools idxstats, samtools stats, picard CollectMultipleMetrics, picard MarkDuplicates, Preseq, deepTools plotProfile, deepTools plotFingerprint and featureCounts.


```{r download multiqc, echo=FALSE, results="asis"}
url <- if(!is.null(report_params$multiqc_url)) report_params$multiqc_url else ""
if (url == "") {
  cat("<p><em>This file was not included in this report.</em></p>")
} else {
  cat(sprintf('<a href="%s" class="btn btn-primary" role="button" download>Download MultiQC Report</a>', url))
}
```

```{r load data,message=FALSE,echo=FALSE,results='hide'}
source("R/data_preparation.R")

# NEW: Use flexible data preparation
analysis_data <- prepare_analysis_data(report_params)

# Extract components (same variable names as before for compatibility)
targetGenome_dds <- analysis_data$dds
sample_info <- analysis_data$sample_info  
peaks_anno <- analysis_data$peaks_anno
qc_data <- analysis_data$qc_data

targetGenome_counts <- assay(targetGenome_dds, "counts")

# Load  sample_info
sample_info <- read.csv(report_params$sample_sheet, stringsAsFactors = FALSE)

# Remove the technical replicate suffix added by nf-core
sample_info$sample <- gsub("_T\\d+", "", sample_info$sample)

# Remove fastq-related columns and keep unique rows
sample_info <- sample_info %>%
  select(-starts_with("fastq")) %>%
  distinct()

# If sample_id column is missing, create it from sample
if (!"sample_id" %in% colnames(sample_info)) {
  sample_info$sample_id <- sample_info$sample
}

# Match and align sample_info to dds$sample. This will definitely match if the sample_sheet is based on what was used for nf-core.
sample_info_matched <- sample_info[match(targetGenome_dds$sample, sample_info$sample), ]

# Sanity check with custom error
if (!identical(sample_info_matched$sample, as.character(targetGenome_dds$sample))) {
  stop('Sample names in the nf-core dds object do not match those in the sample sheet. Ensure the "sample" column has not been changed. Use "sample_id" for custom labels.')
}

# Add all non-duplicate, non-sample_id columns to colData
meta_cols <- setdiff(colnames(sample_info_matched), c("sample", colnames(colData(targetGenome_dds))))
colData(targetGenome_dds)[meta_cols] <- sample_info_matched[meta_cols]

# Updated spike-in loading logic - prioritize direct file path over directory
if (!is.null(report_params$spikein_dds) && report_params$spikein_dds != "" && file.exists(report_params$spikein_dds)) {
  # Method 1: Direct spike-in DDS file path (new approach)
  message("ðŸ”„ Loading spike-in DDS from direct file path: ", basename(report_params$spikein_dds))
  load(report_params$spikein_dds)
  spikeIn_dds <- dds
  rm(dds)
  message("âœ… Spike-in DDS loaded successfully")
} else if (!is.null(report_params$nfcore_spikein_dir) && report_params$nfcore_spikein_dir != "") {
  # Method 2: Legacy directory-based approach (fallback)
  spikein_file <- paste0(report_params$nfcore_spikein_dir, "/bowtie2/merged_library/macs2/broad_peak/consensus/deseq2/consensus_peaks.mLb.clN.dds.RData")
  if (file.exists(spikein_file)) {
    message("ðŸ”„ Loading spike-in DDS from nfcore directory: ", basename(spikein_file))
    load(spikein_file)
    spikeIn_dds <- dds
    rm(dds)
    message("âœ… Spike-in DDS loaded successfully")
  } else {
    message("âš ï¸ Spike-in directory provided but file not found: ", spikein_file)
  }
} else {
  message("â„¹ï¸ No spike-in data provided - will use TMM normalization")
}
```

# Data Pre-processing and Normalization

## Peak Calling and Consensus Peakset Generation

```{r peak_calling_text, echo=FALSE, results='asis'}
peak_calling_description <- get_peak_calling_text(
  peak_caller = report_params$peak_caller,
)

knitr::asis_output(peak_calling_description)
```

## Normalization

```{r normalization_text, echo=FALSE, results='asis'}
norm_text <- get_normalization_text(
  has_spike_in = exists("spikeIn_dds"),
  organism = report_params$organism
)

knitr::asis_output(norm_text)
```

```{r make DGEList and norm}
# === Normalize counts and construct DGEList ===
targetGenome_counts <- assay(targetGenome_dds, "counts")

if (exists("spikeIn_dds")) {
  # --- Spike-in normalization ---
  spikein_counts <- assay(spikeIn_dds, "counts")
  common_samples <- intersect(colnames(targetGenome_counts), colnames(spikein_counts))
  
  # Subset to common samples
  targetGenome_counts <- targetGenome_counts[, common_samples]
  spikein_counts <- spikein_counts[, common_samples]
  targetGenome_dds <- targetGenome_dds[, common_samples]
  spikeIn_dds <- spikeIn_dds[, common_samples]
  
  # Compute spike-in normalization factors
  targetGenome_libsizes <- colSums(targetGenome_counts)
  spikein_libsizes <- colSums(spikein_counts)
  spikein_ratio <- spikein_libsizes / targetGenome_libsizes
  spikein_factors <- spikein_ratio / median(spikein_ratio)
  norm_factors <- 1 / spikein_factors
  
  # Create normalized DGEList
  dge <- DGEList(counts = targetGenome_counts)
  dge$samples <- cbind(dge$samples, as.data.frame(colData(targetGenome_dds)))
  dge$samples$norm.factors <- norm_factors

} else {
  # --- TMM normalization ---
  cat("Spike-in data not available. Performing TMM normalization instead.\n")
  suppressMessages(library(edgeR))
  dge <- DGEList(counts = targetGenome_counts)
  dge$samples <- cbind(dge$samples, as.data.frame(colData(targetGenome_dds)))
  dge <- calcNormFactors(dge, method = "TMM")
  norm_factors <- dge$samples$norm.factors
}
# === Raw DGEList for unnormalized PCA ===
dge_raw <- dge
dge_raw$samples$norm.factors <- rep(1, ncol(dge_raw))
```

## Sample Summary

```{r sample info}
# Update analysis_data with the normalized size factors
colData(analysis_data$dds)$sizeFactor <- dge$samples$norm.factors
atac_qc_table <- summarize_atac_sample_qc(analysis_data, render_table = FALSE)
DT::datatable(atac_qc_table, options = list(pageLength = 20, dom = 't'), rownames = FALSE)
```

## Download Raw and Normalized Consensus Peak Counts Data

**Description of Data Sheets:**

1. **Raw**: Original read counts per consensus peak from featureCounts analysis, before any normalization. Use for alternative analysis pipelines or tools requiring raw counts.

2. **Normalized**: Count values adjusted for library size and compositional differences between samples (TMM or spike-in normalized). These represent the "corrected" counts accounting for technical variation.

3. **CPM**: Counts per million reads, normalized for both library size and sample composition. Useful for comparing relative accessibility between peaks and samples.

4. **LCPM**: Logâ‚‚-transformed CPM values. These are typically used for visualization (PCA plots, heatmaps) and downstream statistical analysis.

5. **Peak_Annotations**: Genomic coordinates (chromosome, start, end, width) for each consensus peak, plus any available gene annotations.

6. **Sample_Metadata**: Sample information including library sizes, normalization factors, and experimental metadata.

The Excel file containing these datasets can be downloaded using the link below.

```{r downloads}
# Load necessary libraries
library(openxlsx)
library(dplyr)

# Description of Data Sheets:
# 1. **Raw**: Raw consensus peak count matrix before normalization
# 2. **Normalized**: Normalized peak counts (TMM or spike-in adjusted, scaled to mean library size)
# 3. **CPM**: Counts per million normalized for library size and composition
# 4. **LCPM**: Log-transformed CPM values, useful for visualization
# 5. **Peak_Annotations**: Consensus peak genomic coordinates and annotations
# 6. **Sample_Metadata**: Sample information including normalization factors and library sizes


# Create peak annotations
peak_annotations <- analysis_data$peaks_anno

# Extract raw counts
raw_counts_df <- as.data.frame(dge_raw$counts)  # Use dge_raw (norm.factors = 1)
raw_counts_df$Peak_ID <- rownames(raw_counts_df)
raw_counts_df <- raw_counts_df %>% select(Peak_ID, everything())

# Calculate normalized counts (using existing normalization factors)
normalized_counts <- cpm(dge, normalized.lib.sizes = TRUE) * mean(dge$samples$lib.size) / 1e6
normalized_counts_df <- as.data.frame(normalized_counts)
normalized_counts_df$Peak_ID <- rownames(normalized_counts_df)
normalized_counts_df <- normalized_counts_df %>% select(Peak_ID, everything())

# Calculate CPM values (normalized for library size and composition)
cpm_values <- cpm(dge, normalized.lib.sizes = TRUE)
cpm_df <- as.data.frame(cpm_values)
cpm_df$Peak_ID <- rownames(cpm_df)
cpm_df <- cpm_df %>% select(Peak_ID, everything())

# Calculate log CPM values
lcpm_values <- cpm(dge, normalized.lib.sizes = TRUE, log = TRUE)
lcpm_df <- as.data.frame(lcpm_values)
lcpm_df$Peak_ID <- rownames(lcpm_df)
lcpm_df <- lcpm_df %>% select(Peak_ID, everything())

# Extract sample metadata (includes normalization factors)
sample_metadata <- dge$samples

# Create Excel export list
peak_data_list <- list(
  "Raw" = raw_counts_df,
  "Normalized" = normalized_counts_df,
  "CPM" = cpm_df,
  "LCPM" = lcpm_df,
  "Peak_Annotations" = peak_annotations,
  "Sample_Metadata" = sample_metadata
)

# Generate download button
peak_data_list %>% downloadthis::download_this(
  output_name = "ATACseq_Consensus_Peaks_Data",
  output_extension = ".xlsx",
  button_label = "Download Consensus Peak Data Counts File",
  button_type = "primary",
  has_icon = TRUE,
  icon = "fa fa-save"
)
```

```{r contrast-load}
contrast_input <- report_params$contrasts
contrast_list <- parse_contrasts(contrast_input)

num_of_contrasts <- length(contrast_list)
contrast_strings <- sapply(seq_along(contrast_list), function(i) {
  paste0(i, ". ", contrast_list[[i]][1], " vs ", contrast_list[[i]][2])
})
```

## Quality Control Plots

```{r setup_norm_titles, echo=FALSE}
# Setup normalization-specific plot titles and labels
if (exists("spikeIn_dds")) {
  norm_method_title <- "Spike-in Normalized"
  pca_combined_title <- "PCA Comparison: Raw vs Spike-in Normalized"
} else {
  norm_method_title <- "TMM Normalized"
  pca_combined_title <- "PCA Comparison: Raw vs TMM Normalized"
}
```

### PCA Plots

```{r pca_text, echo=FALSE,results='asis'}
if (exists("spikeIn_dds")) {
  pca_header <- "Principal Component Analysis (PCA) plots are used here to visualize the overall structure of the data. Two PCA plots are shown:
- **Library Size Normalized (LCPM):** Variance between samples after basic library size normalization (counts per million) but without compositional bias correction.
- **Spike-in Normalized:** Variance after spike-in normalization, where normalization factors were calculated based on spike-in controls to adjust for both library size and compositional biases.
The side-by-side comparison highlights the effect of spike-in normalization over basic CPM normalization on sample clustering."
  pca_combined_title <- "PCA Comparison: LCPM vs Spike-in Normalized"
} else {
  pca_header <- "Principal Component Analysis (PCA) plots are used here to visualize the overall structure of the data. Two PCA plots are shown:
- **Library Size Normalized (LCPM):** Variance between samples after basic library size normalization (counts per million) but without compositional bias correction.
- **TMM Normalized:** Variance after TMM normalization, which adjusts for both library size differences and compositional biases between samples.
The side-by-side comparison highlights the effect of TMM normalization over basic CPM normalization on sample clustering."
  pca_combined_title <- "PCA Comparison: CPM vs TMM Normalized"
}
knitr::asis_output(pca_header)
```

```{r pca plot}
library(plotly)

# Create PCA plots
pca_raw <- plot_pca(dge_raw, title = "PCA - CPM Normalized", show_legend = FALSE)
pca_norm <- plot_pca(dge, title = paste0("PCA - ", norm_method_title), show_legend = TRUE)

# Display plots side by side with individual titles
subplot(
  pca_raw$plot,
  pca_norm$plot,
  nrows = 1,
  titleX = TRUE,
  titleY = TRUE,
  margin = 0.08
) %>%
layout(
  width = 1100,
  height = 500,
  annotations = list(
    list(
      text = pca_raw$title,
      x = 0.25, y = 1.02,
      xref = "paper", yref = "paper",
      xanchor = "center", yanchor = "bottom",
      showarrow = FALSE,
      font = list(size = 14)
    ),
    list(
      text = pca_norm$title,
      x = 0.75, y = 1.02,
      xref = "paper", yref = "paper",
      xanchor = "center", yanchor = "bottom",
      showarrow = FALSE,
      font = list(size = 14)
    )
  )
)
```

### Correlation Heatmaps

```{r corr_text, echo=FALSE,results='asis', eval = !params$test_mode}
if (exists("spikeIn_dds")) {
  corr_header <- "The correlation heatmaps shown here represent the pairwise correlation between samples based on their log-transformed counts per million (LCPM). Two sets of heatmaps are presented:

- **Raw Counts:** The first heatmap shows the sample correlation using raw counts, providing an overview of how similarly the samples behave without any normalization.
- **Spike-in Normalized Counts:** The second heatmap illustrates the correlation between samples after spike-in normalization, which helps account for technical variation and improve comparability between samples.

These heatmaps help assess the overall quality of the samples and identify potential batch effects or outliers in the dataset."
} else {
  corr_header <- "The correlation heatmaps shown here represent the pairwise correlation between samples based on their log-transformed counts per million (CPM). Two sets of heatmaps are presented:

- **Raw Counts:** The first heatmap shows the sample correlation using LCPM of raw counts, providing an overview of how similarly the samples behave without any normalization.
- **TMM Normalized Counts:** The second heatmap illustrates the correlation between samples after TMM normalization, which adjusts for library size differences without the use of spike-in controls.

These heatmaps help assess the overall quality of the samples and identify potential batch effects or outliers in the dataset."
}

knitr::asis_output(corr_header)
```

```{r corr heatmaps, eval = !params$test_mode}
# Correlation heatmaps from log2 CPM
logcpm_raw  <- cpm(dge_raw, log = TRUE)
logcpm_norm <- cpm(dge, log = TRUE)

cor_raw  <- cor(logcpm_raw)
cor_norm <- cor(logcpm_norm)

# Plot side-by-side
par(mfrow = c(1, 2))

pheatmap(cor_raw, main = "Sample Correlation - Raw")
pheatmap(cor_norm, main = paste0("Sample Correlation - ", norm_method_title))
```

```{r annotate consensus peaks}
# === 1. Use already loaded annotation from analysis_data ===
# peaks_anno was already loaded in the "load data" chunk
# No need to reload - just format it for consistency

# === 2. Standardize column names (handle different annotation sources) ===
# Handle HOMER format (from nf-core) vs ChIPseeker format (generated in R)
if ("Chr" %in% colnames(peaks_anno) && "Start" %in% colnames(peaks_anno)) {
  # HOMER format - already has Chr, Start, End
  chr_col <- "Chr"
  start_col <- "Start" 
  end_col <- "End"
} else if ("seqnames" %in% colnames(peaks_anno) && "start" %in% colnames(peaks_anno)) {
  # ChIPseeker format - has seqnames, start, end
  chr_col <- "seqnames"
  start_col <- "start"
  end_col <- "end"
} else {
  stop("Cannot identify chromosome/position columns in peak annotation")
}

# Ensure interval column is named consistently
if (!"interval" %in% colnames(peaks_anno)) {
  colnames(peaks_anno)[1] <- "interval"
}

# === 3. Create GRanges ===
peak_gr <- GRanges(
  seqnames = peaks_anno[[chr_col]],
  ranges = IRanges(start = peaks_anno[[start_col]], end = peaks_anno[[end_col]])
)
names(peak_gr) <- peaks_anno$interval

# Store in rownames if needed
rownames(peaks_anno) <- peaks_anno$interval

# === 4. Add simplified annotation if it doesn't exist ===
if (!"Annotation_short" %in% colnames(peaks_anno)) {
  if ("Annotation" %in% colnames(peaks_anno)) {
    peaks_anno$Annotation_short <- gsub(" .*", "", peaks_anno$Annotation)
  } else if ("annotation" %in% colnames(peaks_anno)) {
    peaks_anno$Annotation_short <- gsub(" .*", "", peaks_anno$annotation)
  }
}
```

## Quality Control Filtering

To ensure that only high-quality samples were included in the differential accessibility analysis, we filtered samples based on their FRiP (Fraction of Reads in Peaks) scores. FRiP reflects how well the reads align to identified peaks â€” a key quality metric in ATAC-seq. According to ENCODE guidelines, FRiP should be at least 20%, with values over 30% considered high quality. Samples with FRiP scores below 20% were excluded from further analysis.

```{r frip filter}
# Report threshold and results
frip_threshold <- 20

# Check if FRiP scores are available
frip_available <- !all(is.na(atac_qc_table$FRIP))

if (frip_available) {
  # FRiP scores available - perform filtering
  samples_with_frip <- !is.na(atac_qc_table$FRIP)
  high_quality_samples <- atac_qc_table$Sample[samples_with_frip & atac_qc_table$FRIP >= frip_threshold]
  low_quality_samples <- atac_qc_table$Sample[samples_with_frip & atac_qc_table$FRIP < frip_threshold]
  missing_frip_samples <- atac_qc_table$Sample[!samples_with_frip]
  
  cat(sprintf("We excluded **%d** sample(s) with FRiP < %d%%. **%d** high-quality samples were retained.\n\n",
              length(low_quality_samples), frip_threshold, length(high_quality_samples)))
  
  # Display dropped samples and their FRiP scores
  if (length(low_quality_samples) > 0) {
    dropped_df <- atac_qc_table[atac_qc_table$Sample %in% low_quality_samples, c("Sample", "FRIP")]
    colnames(dropped_df) <- c("Sample", "FRiP (%)")
    knitr::kable(dropped_df, format = "html", digits = 1, row.names = FALSE)
  } else {
    cat("No samples were dropped based on FRiP filtering.\n")
  }
  
  # Report samples with missing FRiP if any
  if (length(missing_frip_samples) > 0) {
    cat(sprintf("\n**Note**: %d sample(s) had missing FRiP scores and were retained by default: %s\n", 
                length(missing_frip_samples), paste(missing_frip_samples, collapse = ", ")))
  }
  
} else {
  # No FRiP scores available - skip filtering
  high_quality_samples <- atac_qc_table$Sample
  cat(sprintf("**FRiP scores not available** - skipping FRiP-based quality filtering. All **%d** samples were retained.\n\n", 
              length(high_quality_samples)))
  cat("*Note: FRiP (Fraction of Reads in Peaks) filtering could not be performed due to missing QC data.*\n")
}
```

```{r frip drop}
# Drop low-FRiP samples from the dge used for DA analysis
dge <- dge[, colnames(dge) %in% high_quality_samples]
```

```{r analysis}
# Source the file to define the function
invisible(
  suppressMessages(
    suppressWarnings(
      capture.output(source("R/analysis.R", local = knitr::knit_global()))
    )
  )
)

# Now call the function with the required parameters
results_list <- run_differential_analysis(
  dge = dge, 
  peaks_anno = analysis_data$peaks_anno, 
  contrast_strings = contrast_strings,
  report_params = report_params
)
```

# Differential Accessibility Analysis

Differential accessibility analysis of the peak count matrix was performed using the R package edgeR v. 3.4 (McCarthy et al. 2012)[^1] to identify peaks with statistically significant differences in accessibility between conditions in each contrast. For each contrast, samples were subset to the two comparison groups, and peaks were filtered using filterByExpr() with minimum count and proportion thresholds to retain reliably detected peaks. Biological variation (dispersion) was estimated using estimateDisp(), and a quasi-likelihood generalized linear model was fitted using glmQLFit() with the formula ~0 + Condition. Differential accessibility testing was performed using glmQLFTest() to identify peaks with statistically significant changes between conditions.

## Overview of Contrasts

```{r contrast print}
# Print formatted output
cat(
  paste0(
    "The following ", num_of_contrasts, 
    " contrasts were tested for differential accessibility:\n",
    paste(contrast_strings, collapse = "\n")
  )
)
```

## Summary of Differential Accessibility per-contrast

In the per-contrast summary tables below, the "significance" column indicates the "direction" of the significant results (in what group the peak is more accessible), and the number of peaks indicates the number of peaks that are significantly more accessible (FDR < 0.05) in that group. Consensus peaks that were not significantly different between the two groups in the contrast are reported as "Not significant".

```{r summary}
# Helper function to clean group names (remove X prefix from numeric starts)
clean_group_name <- function(name) {
  # Remove X prefix if the rest starts with a number
  if (grepl("^X\\d", name)) {
    return(substring(name, 2))
  }
  return(name)
}

# Create a summary table per contrast
summary_tables <- lapply(names(results_list), function(contrast) {
  df <- results_list[[contrast]]$table
  contrast_clean <- gsub("\\.", "-", contrast)
  df$contrast <- contrast_clean
  
  # Split contrast and clean group names
  groups <- strsplit(contrast, "_vs_")[[1]]
  group1_clean <- clean_group_name(groups[1])
  group2_clean <- clean_group_name(groups[2])
  
  df <- df %>%
    mutate(significance = case_when(
      FDR < 0.05 & logFC > 0 ~ paste("More Accessible (", group1_clean, ")"),
      FDR < 0.05 & logFC < 0 ~ paste("More Accessible (", group2_clean, ")"),
      TRUE ~ "Not Significant"
    ))
  summary <- df %>%
    dplyr::count(significance) %>%
    mutate(Contrast = paste(group1_clean, "vs", group2_clean)) %>%  # Use cleaned names for display
    select(Contrast, everything())
  return(summary)
})

# Render the summary tables using tagList and DT::datatable
output_tables <- lapply(summary_tables, function(df) {
  # Extract clean group names for styling
  contrast_parts <- strsplit(df$Contrast[1], " vs ")[[1]]
  group1_clean <- contrast_parts[1]
  group2_clean <- contrast_parts[2]
  
  datatable(
    df %>% rename("number of peaks" = "n"),
    caption = paste("Summary of Differential Peak Accessibility for contrast:", df$Contrast[1]),
    options = list(dom = 't', ordering = FALSE),
    rownames = FALSE
  ) %>%
    formatStyle(
      'significance',
      target = 'row',
      backgroundColor = styleEqual(
        c(paste("More Accessible (", group1_clean, ")"),
          paste("More Accessible (", group2_clean, ")"),
          "Not Significant"),
        c("lightblue", "lightcoral", "lightgray")
      )
    )
})

# Use tagList to render the tables properly in the report
tagList(output_tables)
```

## Downloadable Results Tables

```{r annotation_description, echo=FALSE, results='asis'}
annotation_text <- get_annotation_description_text(peaks_anno)
knitr::asis_output(annotation_text)
```

```{r make downloads, message=FALSE, warning=FALSE,eval = !params$test_mode}
library(dplyr)
library(stringr)
library(downloadthis)
library(htmltools)

# Helper function to clean group names (remove X prefix from numeric starts)
clean_group_name <- function(name) {
  # Remove X prefix if the rest starts with a number
  if (grepl("^X\\d", name)) {
    return(substring(name, 2))
  }
  return(name)
}

# STEP 1: Create in-memory data frame lists (but don't write to disk)
promoter_lists <- list()
allregion_lists <- list()
for (cn in names(results_list)) {
  cn_clean <- gsub("\\.", "-", cn)  # Restores the original contrast name with "-"
  contrast_data <- results_list[[cn]]$table
  parts <- str_split(cn_clean, "_vs_", simplify = TRUE)
  left <- clean_group_name(parts[1])      # Clean group names
  right <- clean_group_name(parts[2])     # Clean group names
  
  # Create clean contrast name for display
  cn_display <- paste(left, "vs", right)
  
  # Promoter regions - handle both HOMER and ChIPseeker column names
  distance_col <- if ("Distance.to.TSS" %in% colnames(contrast_data)) {
    "Distance.to.TSS"  # HOMER format
  } else if ("distanceToTSS" %in% colnames(contrast_data)) {
    "distanceToTSS"    # ChIPseeker format  
  } else if ("DistanceToTSS" %in% colnames(contrast_data)) {
    "DistanceToTSS"    # Alternative ChIPseeker format
  } else {
    stop("Cannot find distance to TSS column in annotation data")
  }
  
  # Promoter regions
  prom_df <- contrast_data %>% filter(FDR < 0.05, abs(.data[[distance_col]]) < 1000)
  prom_left <- prom_df %>% filter(logFC > 0)
  prom_right <- prom_df %>% filter(logFC < 0)
  promoter_lists[[cn_display]] <- setNames(  # Use cleaned display name
    list(prom_left, prom_right),
    c(paste0("More acc. in ", left), paste0("More acc. in ", right))
  )
  
  # All annotated regions
  all_df <- contrast_data %>% filter(FDR < 0.05)
  all_left <- all_df %>% filter(logFC > 0)
  all_right <- all_df %>% filter(logFC < 0)
  allregion_lists[[cn_display]] <- setNames(  # Use cleaned display name
    list(all_left, all_right),
    c(paste0("More acc. in ", left), paste0("More acc. in ", right))
  )
}

# STEP 2: Create download buttons (no filepaths used)
promoter_buttons <- purrr::map2(promoter_lists, names(promoter_lists), function(datalist, cn_display) {
  download_this(
    .data = datalist,
    output_name = paste0(report_params$seqID,"_Differential_Accessibility_Promoter_", gsub(" vs ", "_vs_", cn_display)),
    button_label = paste0(report_params$seqID,"_DA Promoter Peaks:<br>", cn_display),
    button_type = "primary",
    output_extension = ".xlsx"
  )
})

allregion_buttons <- purrr::map2(allregion_lists, names(allregion_lists), function(datalist, cn_display) {
  download_this(
    .data = datalist,
    output_name = paste0(report_params$seqID,"_Differential_Accessibility_All_Regions_", gsub(" vs ", "_vs_", cn_display)),
    button_label = paste0(report_params$seqID,"_DA All Region Peaks:<br>", cn_display),
    button_type = "info",
    output_extension = ".xlsx"
  )
})
```

```{r download table,eval = !params$test_mode}
knitr::asis_output(
  paste(
    "<h3>Download Differential Accessibility Results</h3>",
    "<table class='table table-striped'>",
    "<thead><tr><th>Contrast</th><th>DA Promoter Regions</th><th>DA All Annotated Regions</th></tr></thead>",
    "<tbody>",
    paste0(
      lapply(seq_along(promoter_lists), function(i) {
        cn <- names(promoter_lists)[i]  # This is now the cleaned display name
        paste(
          "<tr>",
          "<td><strong>", cn, "</strong></td>",
          "<td>", promoter_buttons[[i]], "</td>",
          "<td>", allregion_buttons[[i]], "</td>",
          "</tr>"
        )
      }),
      collapse = ""
    ),
    "</tbody></table>"
  )
)
```

# Visualization of Differential Accessibility

## WashU Epigenome Browser Datahubs
WashU datahubs were generated for each contrast to support interactive visualization of differential accessibility results. These datahubs allow genomic regions of interest to be viewed alongside signal tracks from individual samples in the WashU Epigenome Browser.

For each contrast, a set of filtered differentially accessible (DA) peaks was converted to BigBed format for browser visualization. **Peaks were filtered to retain those with a false discovery rate (FDR) less than 0.05, an absolute log2 fold change greater than 1, an average accessibility (logCPM) greater than 2, and an annotated gene name.** These filtered peaks were included as a track within the datahub.

Datahubs also include BigWig signal tracks for each individual sample, colored by experimental group to compare accessibility profiles across replicates and conditions in the genome browser. All datahubs are hosted on a web-accessible directory and accessible via the WashU Epigenome Browser.

**Clicking the "WashU Browser" links in the table below will open the tracks in the WashU Epigenome Browser.** Make sure to right click and select open a new tab if you do not want to navigate away from this report.

```{r create washU datahubs, eval = !params$test_mode, results='hide', message=FALSE, echo=FALSE}
library(jsonlite)

# Helper function to copy file to web directory
copy_file_to_web <- function(source_path, dest_dir, filename) {
  if (file.exists(source_path)) {
    dest_path <- file.path(dest_dir, filename)
    file.copy(source_path, dest_path, overwrite = TRUE)
    system2("chmod", args = c("644", dest_path))
    return(TRUE)
  }
  return(FALSE)
}

create_da_bigbed <- function(results_df, contrast_name, output_dir, organism) {
  # Filter significant peaks
  sig_peaks <- results_df %>%
    filter(FDR < 0.05, abs(logFC) > 1, logCPM > 2, !is.na(Gene.Name))
  
  if (nrow(sig_peaks) == 0) {
    cat("No significant peaks found for", contrast_name, "\n")
    return(NULL)
  }
  
  # Extract group names from contrast for direction annotation
  group_names <- strsplit(contrast_name, "_vs_")[[1]]
  group1 <- group_names[1]
  group2 <- if(length(group_names) > 1) group_names[2] else "baseline"
  
  # Detect column names flexibly (HOMER vs ChIPseeker compatibility)
  chr_col <- if ("Chr" %in% colnames(sig_peaks)) "Chr" else "seqnames"
  start_col <- if ("Start" %in% colnames(sig_peaks)) "Start" else "start"
  end_col <- if ("End" %in% colnames(sig_peaks)) "End" else "end"
  strand_col <- if ("Strand" %in% colnames(sig_peaks)) "Strand" else "strand"
  
  # Debug: show detected columns
  cat("Detected columns for", contrast_name, ":\n")
  cat("  Chr:", chr_col, "Start:", start_col, "End:", end_col, "Strand:", strand_col, "\n")
  
  # Create BED format data with directional annotations
  bed_data <- sig_peaks %>%
    mutate(
      Chr = as.character(.[[chr_col]]),
      Start = .[[start_col]],
      End = .[[end_col]],
      Strand = if (strand_col %in% colnames(.)) .[[strand_col]] else ".",
      # Create directional peak names
      base_name = ifelse(!is.na(Gene.Name) & Gene.Name != "", Gene.Name, interval),
      direction_suffix = ifelse(logFC > 0, 
                               paste0("_MORE_ACC_IN_", toupper(group1)), 
                               paste0("_MORE_ACC_IN_", toupper(group2))),
      peak_name = paste0(base_name, direction_suffix)
    ) %>%
    select(Chr, Start, End, peak_name, logFC, FDR, Strand) %>%
    mutate(
      Chr = ifelse(grepl("^chr", Chr), Chr, paste0("chr", Chr)),
      # Convert scores to integers (BED format requirement)
      score = as.integer(ifelse(logFC > 0,
                               pmin(1000, pmax(600, 600 + abs(logFC) * 100)), # Up: 600-1000
                               pmin(500, pmax(200, 500 - abs(logFC) * 100)))), # Down: 200-500
      strand = Strand  # Rename to standard lowercase for BED output
    ) %>%
    select(Chr, Start, End, peak_name, score, strand)  # Final BED format
  
  # Debug output
  cat("Sample directional peak names for", contrast_name, ":\n")
  sample_names <- head(bed_data$peak_name, 3)
  cat(paste(sample_names, collapse = "\n"), "\n")
  cat("Sample scores:", head(bed_data$score, 3), "\n\n")
  
  # Write BED file (unsorted)
  bed_file <- file.path(output_dir, paste0(contrast_name, "_DA_peaks.bed"))
  write.table(bed_data, bed_file, sep = "\t", quote = FALSE, row.names = FALSE, col.names = FALSE)
  
  # Sort with system command (bedToBigBed requires this exact sorting)
  sorted_bed_file <- file.path(output_dir, paste0(contrast_name, "_DA_peaks_sorted.bed"))
  system2("sort", args = c("-k1,1", "-k2,2n", bed_file), stdout = sorted_bed_file,
          env = c("LC_COLLATE=C"))
  
  # Set up for BigBed conversion
  chrom_sizes_file <- if (organism == "mmu") "mm10.chrom.sizes" else "hg38.chrom.sizes"
  genome_alias <- if (organism == "mmu") "mm10" else "hg38"
  
  # Download chrom.sizes if needed
  if (!file.exists(chrom_sizes_file)) {
    download.file(
      paste0("http://hgdownload.soe.ucsc.edu/goldenPath/", genome_alias, "/bigZips/", genome_alias, ".chrom.sizes"),
      chrom_sizes_file
    )
  }
  
  # Find bedToBigBed
  bedToBigBed_path <- Sys.which("bedToBigBed")
  if (bedToBigBed_path == "") {
    alt_path <- "/apps/ucsc/20210803/bedToBigBed"
    if (file.exists(alt_path)) {
      bedToBigBed_path <- alt_path
    } else {
      stop("bedToBigBed not found")
    }
  }
  
  # Convert to BigBed
  bigbed_file <- file.path(output_dir, paste0(contrast_name, "_DA_peaks.bb"))
  result <- system2(bedToBigBed_path, args = c(sorted_bed_file, chrom_sizes_file, bigbed_file),
                   stdout = TRUE, stderr = TRUE)
  
  # Check if conversion succeeded
  if (file.exists(bigbed_file) && file.size(bigbed_file) > 1000) {
    system2("chmod", args = c("644", bigbed_file))
    cat("Successfully created BigBed:", basename(bigbed_file), "\n")
    return(paste0(contrast_name, "_DA_peaks.bb"))
  } else {
    cat("BigBed conversion failed for", contrast_name, "\n")
    if (length(result) > 0) cat("Error:", paste(result, collapse = "\n"), "\n")
    return(NULL)
  }
}

# Create datahubs for each contrast
washU_urls <- list()
base_web_dir <- "/orange/cancercenter-dept/web/public/BCB-SR/washU"
base_web_url <- "https://data.rc.ufl.edu/pub/cancercenter-dept/BCB-SR/washU"

for (contrast in names(results_list)) {
  contrast_clean <- gsub("\\.", "_", contrast)
  
  # Clean the contrast name by removing X prefixes  
  parts <- strsplit(contrast_clean, "_vs_")[[1]]
  contrast_clean <- paste(clean_group_name(parts[1]), "vs", clean_group_name(parts[2]), sep = "_")
  
  # Create output directory - use slash structure: /washU/NS3971/04D_vs_67D/
  project_dir <- file.path(base_web_dir, report_params$seqID, contrast_clean)
  dir.create(project_dir, recursive = TRUE, showWarnings = FALSE)
  
  # Extract groups from contrast and clean them
  groups <- strsplit(contrast, "_vs_")[[1]]
  group1 <- clean_group_name(groups[1])
  group2 <- clean_group_name(groups[2])
  
  # Group colors
  group_colors <- list()
  group_colors[[group1]] <- "blue"
  group_colors[[group2]] <- "red"
  
  # Initialize tracks list
  tracks <- list()
  
  # Add DA peaks track
  da_bigbed <- create_da_bigbed(
    results_list[[contrast]]$table,
    contrast_clean,
    project_dir,
    report_params$organism
  )
  # Determine ensemblStyle based on annotation source
use_ensembl_style <- if (!is.null(analysis_data[["file_specs"]]$peak_annotation) && file.exists(analysis_data[["file_specs"]]$peak_annotation)) {
  TRUE   # Using existing HOMER annotation file
} else {
  FALSE  # Using generated ChIPseeker annotation (we added chr prefixes)
}
  if (!is.null(da_bigbed)) {
    tracks <- append(tracks, list(list(
      type = "bigbed",
      name = paste("DA Peaks", contrast_clean),
      url = paste0(base_web_url, "/", report_params$seqID, "/", contrast_clean, "/", da_bigbed),
      showOnHubLoad = TRUE,
      options = list(
        height = 60,
        color = "black",
        ensemblStyle = TRUE
      )
    )))
  }
  
  # Clean condition names in dge object to match our cleaned group names
  dge$samples$Condition <- sapply(dge$samples$Condition, clean_group_name)
  
  # Add BigWig tracks for each group
  for (group in c(group1, group2)) {
    # Find samples for this group
    group_samples <- rownames(dge$samples)[dge$samples$Condition == group]
    
    for (sample in group_samples) {
      # Clean the sample name to match bigwig_files keys
      clean_sample <- clean_group_name(sample)  # X04D_REP1 -> 04D_REP1
      
      # Get BigWig file path using cleaned sample name
      if (clean_sample %in% names(analysis_data$bigwig_files)) {
        bigwig_path <- analysis_data$bigwig_files[[clean_sample]]
        
        if (file.exists(bigwig_path)) {
          bigwig_filename <- basename(bigwig_path)
          
          # Copy BigWig to web directory
          if (copy_file_to_web(bigwig_path, project_dir, bigwig_filename)) {
            tracks <- append(tracks, list(list(
              type = "bigwig",
              name = paste(clean_sample, group),
              url = paste0(base_web_url, "/", report_params$seqID, "/", contrast_clean, "/", bigwig_filename),
              showOnHubLoad = TRUE,
              options = list(
                height = 50,
                color = group_colors[[group]],
                ensemblStyle = use_ensembl_style
              )
            )))
          }
        }
      }
    }
  }
  
  # Write datahub.json
  json_file <- file.path(project_dir, "datahub.json")
  writeLines(toJSON(tracks, pretty = TRUE, auto_unbox = TRUE), json_file)
  
  # Set permissions on the project directory and all contents
  system2("chmod", args = c("-R", "o+rX", project_dir))
  
  # Ensure parent directories are traversable
  system2("chmod", args = c("o+rx", base_web_dir))
  parent_seq_dir <- file.path(base_web_dir, report_params$seqID)
  if (dir.exists(parent_seq_dir)) {
    system2("chmod", args = c("o+rx", parent_seq_dir))
  }
  
  # Generate WashU URL
  genome_alias <- if (report_params$organism == "mmu") "mm10" else "hg38"
  datahub_url <- paste0(base_web_url, "/", report_params$seqID, "/", contrast_clean, "/datahub.json")
  washU_url <- paste0("https://epigenomegateway.wustl.edu/browser/?genome=",
                      genome_alias, "&hub=", URLencode(datahub_url))
  
  washU_urls[[contrast]] <- washU_url
}
```

```{r display washU links, eval = !params$test_mode}
# Create table of WashU browser links
washU_links_md <- sapply(names(washU_urls), function(contrast) {
  contrast_clean <- gsub("\\.", " vs ", contrast)
  sprintf("[View in WashU Browser](%s)", washU_urls[[contrast]])
})

knitr::kable(
  data.frame(
    Contrast = gsub("\\.", " vs ", names(washU_links_md)),
    WashU_Browser = washU_links_md
  ),
  format = "markdown",
  row.names = FALSE
)
```

## Barplots of Differential Peak Accessibility by Peak Annotation

Barplots show the number of differentially accessible (DA) peaks within each annotation category (e.g., promoter, intron, intergenic) for each contrast. Peaks were grouped based on their significance and direction of accessibility (i.e., more accessible in one group vs. the other, or not significant).

```{r plot_accessibility_ggplotly, message=FALSE, warning=FALSE, eval = !params$test_mode}
# STEP 1: Combine all contrasts into one long dataframe
all_results <- bind_rows(
  lapply(names(results_list), function(contrast) {
    df <- results_list[[contrast]]$table
    df$contrast <- contrast
    parts <- str_split(contrast, "_vs_", simplify = TRUE)
    left <- str_trim(parts[1])
    right <- str_trim(parts[2])
    
    df <- df %>%
      mutate(significance = case_when(
        FDR < 0.05 & logFC > 0 ~ paste0(right, "\n(More Accessible)"),
        FDR < 0.05 & logFC < 0 ~ paste0(left, "\n(More Accessible)"),
        TRUE ~ "Not Significant"
      ))
    return(df)
  })
)

# STEP 2: One ggplotly plot per contrast
interactive_plots <- lapply(unique(all_results$contrast), function(cn) {
  contrast_df <- all_results %>% filter(contrast == cn)
  contrast_df <- contrast_df %>% filter(!is.na(Annotation_short))
  
  p <- ggplot(contrast_df, aes(x = significance, fill = Annotation_short)) +
    #geom_bar(position = "stack", width = 0.6) +
    geom_bar(stat = "count", position = "stack", width = 0.6) +
    geom_text(stat = "count", aes(label = after_stat(count)), 
          position = position_stack(vjust = 0.5), size = 3)+

    scale_fill_brewer(palette = "Paired") +
    labs(
      title = paste("Consensus Peak Annotation by Accessibility Category:\n", gsub("\\.", "-", cn)),
      x = "Accessibility Category",
      y = "Number of Consensus Peaks",
      fill = "Annotation"
    ) +
    theme_minimal(base_size = 12) +
    theme(
      axis.text.x = element_text(angle = 0, vjust = 1, hjust = 0.5),
      plot.margin = margin(10, 10, 40, 10)
    )
  
  ggplotly(p, tooltip = c("x", "fill", "count"))
})

# STEP 3: Display all interactive plots
tagList(interactive_plots)
```

## MA Plots

MA plots visualize the relationship between average accessibility (log<sub>2</sub> CPM) and differential accessibility (log<sub>2</sub> fold change) for each peak within a given contrast. Each point represents a consensus peak, with its position determined by its average accessibility across all samples (x-axis) and the estimated log fold change between groups (y-axis).

Peaks are colored based on statistical significance and direction of change: red indicates peaks more accessible in one group, blue indicates peaks more accessible in the other, and gray represents non-significant differences. Only peaks with an absolute log<sub>2</sub> fold change greater than 1 and an FDR below 0.05 are considered significant.

These plots are useful for assessing the global characteristics of each contrast â€” for example, whether one group has more widespread accessibility changes, whether there is an even distribution of up- and down-regulated peaks, and whether extreme fold changes are occurring mostly in low-abundance regions (which may reflect noise). They also help confirm that log fold changes are centered around zero in non-significant peaks, as expected when normalization and modeling are appropriately specified.

```{r ma plots, eval = !params$test_mode}
# Reusable preprocessing helper
preprocess_result <- function(df, contrast) {
  groups <- str_trim(str_split(gsub("\\.", "-", contrast), "_vs_", simplify = TRUE))
  df$group1 <- groups[1]
  df$group2 <- groups[2]
  df$Accessibility <- case_when(
    df$FDR < 0.05 & df$logFC > 1  ~ paste0("More accessible in ", df$group1),
    df$FDR < 0.05 & df$logFC < -1 ~ paste0("More accessible in ", df$group2),
    TRUE                          ~ "Not Significant"
  )
  
  df$Significant <- case_when(
    df$FDR < 0.05 & df$logFC > 1  ~ "more",
    df$FDR < 0.05 & df$logFC < -1 ~ "less",
    TRUE                          ~ "ns"
  )
  
  df$negLogFDR <- -log10(df$FDR)
  df
}

# Interactive MA plots with plotly
ma_results <- lapply(names(results_list), function(contrast) {
  df <- preprocess_result(results_list[[contrast]]$table, contrast)

  color_values <- setNames(
    c("red", "blue", "gray"),
    c(
      paste0("More accessible in ", df$group1[1]),
      paste0("More accessible in ", df$group2[1]),
      "Not Significant"
    )
  )
  
  df$color <- color_values[df$Accessibility]

  p <- plot_ly(
    data = df,
    x = ~logCPM,
    y = ~logFC,
    type = 'scatter',
    mode = 'markers',
    text = ~Gene.Name,
    color = ~Accessibility,
    colors = color_values,
    marker = list(size = 5, opacity = 0.6)
  ) %>%
    layout(
      title = list(text = paste("MA Plot: Differential Accessibility in<br>", gsub("\\.", "-", contrast))),
      xaxis = list(title = "log2 CPM"),
      yaxis = list(title = "log2 Fold Change"),
      legend = list(title = list(text = "Accessibility"))
    )

  list(interactive_plot = p)
})

# Display all interactive MA plots
tagList(lapply(ma_results, function(x) x$interactive_plot))

```

## Volcano Plots

Volcano plots summarize the results of differential accessibility analysis by displaying the magnitude of change (log<sub>2</sub> fold change) on the x-axis and statistical significance (â€“log<sub>10</sub> FDR) on the y-axis. Each point represents a consensus peak tested within a given contrast.

Peaks are colored based on statistical significance and direction of change: red indicates peaks more accessible in one group, blue indicates peaks more accessible in the other, and gray represents non-significant differences. Only peaks with an absolute log<sub>2</sub> fold change greater than 1 and an FDR below 0.05 are considered significant.

Volcano plots are used to assess the overall strength and distribution of differential accessibility signals in each contrast. They help reveal whether a contrast has many significant peaks or only a few, whether the effect sizes are modest or extreme, and whether the signal is symmetric or biased toward one condition. Like MA plots, volcano plots serve as a quality check to confirm that differential patterns are consistent with expectations and that significance is not driven solely by low-count or high-variance regions.

```{r volcano, eval = !params$test_mode}
volcano_results <- lapply(names(results_list), function(contrast) {
  df <- preprocess_result(results_list[[contrast]]$table, contrast)

  # Define consistent colors
  color_values <- setNames(
    c("red", "blue", "gray"),
    c(
      paste0("More accessible in ", df$group1[1]),
      paste0("More accessible in ", df$group2[1]),
      "Not Significant"
    )
  )

  df$color <- color_values[df$Accessibility]

  # Create plotly volcano plot
  p <- plot_ly(
    data = df,
    x = ~logFC,
    y = ~negLogFDR,
    type = 'scatter',
    mode = 'markers',
    text = ~Gene.Name,
    color = ~Accessibility,
    colors = color_values,
    marker = list(size = 5, opacity = 0.6)
  ) %>%
    layout(
      title = list(text = paste("Volcano Plot: Differential Accessibility in<br>", gsub("\\.", "-", contrast))),
      xaxis = list(title = "log2 Fold Change"),
      yaxis = list(title = "-log10(FDR)"),
      legend = list(title = list(text = "Accessibility"))
    )

  list(interactive_plot = p)
})

# Display all volcano plots
tagList(lapply(volcano_results, function(x) x$interactive_plot))

```

```{r, eval=FALSE}
### Profile Plots by Group (deepTools)
system2("bash", args = c(
  "bash/make_group_profiles.sh",
  report_params$contrasts,
  report_params$pipeline_output,
  file.path(report_params$outdir, "group_profiles")
))
```

# Pathway Enrichment Analysis

Pathway enrichment analysis was performed to identify functional enrichment of gene lists and to compare these significant results across contrasts.

## Differentially Accessible Genes

To create gene lists to input into enrichment analyses, differentially accessible peaks were filtered by FDR < 0.05 and split into more accessible in left group relative to right group (logFC >1) and less accessible (logFC < 1). From these filtered peaks, those annotated with entrez IDs were selected and these entrez IDs were used as input into the enrichment analysis.

```{r make gene lists, eval = !params$test_mode}
library("AnnotationDbi")
library("clusterProfiler")

if (report_params$organism == "hsa") {
  library("org.Hs.eg.db")
  org_db <- org.Hs.eg.db
} else if (report_params$organism == "mmu") {
  library("org.Mm.eg.db")
  org_db <- org.Mm.eg.db
} else {
  stop("Unsupported organism: must be 'hsa' or 'mmu'")
}

# Convert all results to named gene lists by direction
gene_list_named <- list()
for (contrast in names(results_list)) {
  df <- results_list[[contrast]]$table
  
  # Check if we need to map IDs or if they're already Entrez IDs
  if ("geneId" %in% colnames(df)) {
    # ChIPseeker format - geneId is already Entrez ID
    df$ENTREZID <- as.character(df$geneId)
  } else if ("Entrez.ID" %in% colnames(df)) {
    # Check if Entrez.ID column contains actual Entrez IDs or Ensembl IDs
    sample_id <- df$Entrez.ID[!is.na(df$Entrez.ID)][1]
    
    if (grepl("^ENSMUSG|^ENSG", sample_id)) {
      # These are Ensembl IDs - need to map
      df <- df %>%
        rename(ensembleID = Entrez.ID) %>%
        mutate(
          ENTREZID = as.character(mapIds(
            org_db,
            keys = ensembleID,
            column = "ENTREZID",
            keytype = "ENSEMBL",
            multiVals = "first"
          ))
        )
    } else {
      # These are already Entrez IDs - use directly
      df$ENTREZID <- as.character(df$Entrez.ID)
    }
  } else {
    stop("Cannot find gene ID column in results")
  }
  
  up_genes <- df %>%
    filter(FDR < 0.05, logFC > 1) %>%
    pull(ENTREZID) %>%
    na.omit() %>% unique()
  
  down_genes <- df %>%
    filter(FDR < 0.05, logFC < -1) %>%
    pull(ENTREZID) %>%
    na.omit() %>% unique()
  
  # CLEAN the contrast name before using it
  contrast_clean <- gsub("\\.", "_", contrast)
  
  # Remove X prefixes from contrast name
  parts <- strsplit(contrast_clean, "_vs_")[[1]]
  contrast_clean <- paste(clean_group_name(parts[1]), "vs", clean_group_name(parts[2]), sep = "_")
  
  gene_list_named[[paste0(contrast_clean, ".up")]] <- up_genes
  gene_list_named[[paste0(contrast_clean, ".down")]] <- down_genes
}
```

```{r prep-for-enrich, eval = !params$test_mode}
de_results_df <- bind_rows(lapply(names(results_list), function(contrast) {
  df <- results_list[[contrast]][["table"]]
  df$Contrast <- contrast  # Add the contrast column
  return(df)
}))

# Get universe of gene IDs - handle both annotation formats
if ("geneId" %in% colnames(de_results_df)) {
  # ChIPseeker format - geneId is already Entrez ID
  universe_entrez <- na.omit(unique(de_results_df$geneId))
} else if ("Entrez.ID" %in% colnames(de_results_df)) {
  # Check what type of IDs are in Entrez.ID column
  sample_id <- de_results_df$Entrez.ID[!is.na(de_results_df$Entrez.ID)][1]
  
  if (grepl("^ENSMUSG|^ENSG", sample_id)) {
    # These are Ensembl IDs - need to map to Entrez
    universe_entrez <- mapIds(org_db,
                              keys = na.omit(unique(de_results_df$Entrez.ID)),
                              column = "ENTREZID",
                              keytype = "ENSEMBL", 
                              multiVals = "first")
    universe_entrez <- na.omit(universe_entrez)
  } else {
    # These are already Entrez IDs - use directly
    universe_entrez <- na.omit(unique(de_results_df$Entrez.ID))
  }
} else {
  stop("Cannot find gene ID column in results")
}
```

## Gene Ontology (GO) Enrichment Analysis

Gene Ontology enrichment of gene annotation of differentially accessibile regions was performed using the enrichGO function in clusterProfiler v4.8 (Yu et al. 2012) in each of three GO categories (BP, MF, CC). **Interactive GO enrichment plots** are based on the top 10 significantly enriched GO terms per GO category per gene list. Hover over the plot to view p-value, gene ratio, and up to the top 20 DE genes (sorted by DE adj.p.value) in that term.

To assess similarities between gene lists' enrichment results, if a gene list(s) had significant results for a different gene lists' top-10 term, that result is displayed as well regardless of whether or not the result was in top 10. **Downloadable results excel file** include all significant results for all gene lists.

```{r run GO enrich, eval = !params$test_mode}
# Perform GO Enrichment for BP, MF, CC
GO_BP_results <- generate_enrichment_plot_atac(
  gene_lists = gene_list_named, 
  de_results_df = de_results_df, 
  universe_entrez = universe_entrez,
  ont_category = "BP",
  annotation_db = report_params$annotation_db
)

GO_MF_results <- generate_enrichment_plot_atac(
  gene_lists = gene_list_named, 
  de_results_df = de_results_df, 
  universe_entrez = universe_entrez,
  ont_category = "MF",
  annotation_db = report_params$annotation_db
)

GO_CC_results <- generate_enrichment_plot_atac(
  gene_lists = gene_list_named, 
  de_results_df = de_results_df, 
  universe_entrez = universe_entrez,
  ont_category = "CC",
  annotation_db = report_params$annotation_db
)
```

```{r GO enrich plots,fig.width=12, fig.height=10, eval = !params$test_mode}
# Display interactive plots
download_button_png(GO_BP_results$static_plot, "GO_BP_enrich_plot",height = 12)
GO_BP_results$interactive_plot

download_button_png(GO_MF_results$static_plot, "GO_MF_enrich_plot",height=12)
GO_MF_results$interactive_plot

download_button_png(GO_CC_results$static_plot, "GO_CC_enrich_plot",height=12)
GO_CC_results$interactive_plot

# Combine GO results into a single list of data frames
GO_results_list <- list(
  "BP_Results" = GO_BP_results$go_results,
  "MF_Results" = GO_MF_results$go_results,
  "CC_Results" = GO_CC_results$go_results
)
# Remove NULL elements
GO_results_list <- GO_results_list[!sapply(GO_results_list, is.null)]


# Loop through the list of data frames and apply the substitution
GO_results_list <- lapply(GO_results_list, function(df) {
  df$GeneSymbols <- gsub("<br>", "/", df$GeneSymbols)
  return(df)
})
# Download GO results as an Excel file if any exist
if (length(GO_results_list) > 0) {
  GO_results_list %>% downloadthis::download_this(
    output_name = "GO_results",
    output_extension = ".xlsx",
    button_label = "Download GO enrichment results for all GO categories and all contrasts",
    button_type = "primary",
    has_icon = TRUE,
    icon = "fa fa-save"
  )
} else {
  cat("<b>No GO enrichment results available to download.</b>")
}
```

## KEGG Pathway Enrichment Analysis

KEGG enrichment was performed using the enrichKEGG function in clusterProfiler v4.8 (Yu et al. 2012). **Interactive KEGG enrichment plots** are based on the top 10 significantly enriched KEGG pathways per gene list. Hover over the plot to view p-value, gene ratio, and up to the top 20 DE genes (sorted by DE adj.p.value) in that pathway.

To assess similarities between gene lists' enrichment results, if a gene list(s) had significant results for a different gene lists' top-10 pathway, that result is displayed as well regardless of whether or not the result was in top 10. **Downloadable results excel file** include all significant results for all gene lists.

```{r KEGG, eval=TRUE, message=FALSE, eval = !params$test_mode}
# Run the KEGG enrichment function with error handling
kegg_results <- tryCatch({
  generate_kegg_enrichment_plot_atac(
    gene_lists = gene_list_named, 
    de_results_df = de_results_df, 
    universe_entrez = universe_entrez,
    annotation_db = report_params$annotation_db 
  )
}, error = function(e) {
  message("[INFO] KEGG enrichment was not performed due to no enrichment found in any gene list")
  NULL
})
```

```{r kegg plot,fig.width=12, fig.height=10, eval = !params$test_mode}
# Only proceed if kegg_results is not NULL
if (!is.null(kegg_results)) {
  download_button_png(kegg_results$static_plot, "kegg_enrichment_plot", height = 12)
}

# Display interactive plot (renders automatically when outside braces)
if (!is.null(kegg_results)) kegg_results$interactive_plot

# Continue with data processing
if (!is.null(kegg_results)) {
  kegg_results[["kegg_results"]]$GeneSymbols <- gsub("<br>", "/", kegg_results[["kegg_results"]]$GeneSymbols)
  kegg_results[["kegg_results"]] %>%
    downloadthis::download_this(
      output_name = paste(report_params$seqID, "KEGG_results", sep = "_"),
      output_extension = ".xlsx",
      button_label = "Download KEGG enrichment results for all contrasts",
      button_type = "primary",
      has_icon = TRUE,
      icon = "fa fa-save"
    )
} else {
  cat("### KEGG enrichment was not available for this dataset due to too few DA peaks.\n")
}
```

# References

[^1]: McCarthy DJ, Chen Y and Smyth GK (2012). Differential expression analysis of multifactor RNA-Seq experiments with respect to biological variation. Nucleic Acids Research 40, 4288-4297

[^2]: Patel, H., Espinosa-Carrasco, J., Langer, B., Ewels, P., nf-core bot, Garcia, M. U., Syme, R., Peltzer, A., Talbot, A., Behrens, D., Gabernet, G., Jin, M., HÃ¶rtenhuber, M., Gonzalez Rodriguez, J., Menden, K., & An, Ã–. (2022). nf-core/atacseq: 2.1.2. [GitHub repository]. https://github.com/nf-core/atacseq (accessed August 7, 2022).
